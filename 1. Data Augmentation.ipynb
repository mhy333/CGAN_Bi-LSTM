{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc91e41",
   "metadata": {},
   "source": [
    "# 1. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeac374",
   "metadata": {},
   "source": [
    "# 1.1 CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 12  \n",
    "plt.rcParams['font.weight'] = 'bold' \n",
    "plt.rcParams['axes.titlesize'] = 14  \n",
    "plt.rcParams['axes.labelsize'] = 12   \n",
    "plt.rcParams['axes.titleweight'] = 'bold'  \n",
    "plt.rcParams['axes.labelweight'] = 'bold'  \n",
    "plt.rcParams['xtick.labelsize'] = 10   \n",
    "plt.rcParams['ytick.labelsize'] = 10   \n",
    "plt.rcParams['legend.fontsize'] = 10  \n",
    "plt.rcParams['legend.title_fontsize'] = 12  \n",
    "\n",
    "# Change the data path when test\n",
    "df = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/data/Well_B_MLR.csv')\n",
    "\n",
    "if 'LostCirculation' not in df.columns:\n",
    "    raise ValueError(\"数据集必须包含 'LostCirculation' 列。\")\n",
    "\n",
    "X = df.drop('LostCirculation', axis=1)\n",
    "y = df['LostCirculation']\n",
    "X_min = X.min().values\n",
    "X_max = X.max().values\n",
    "\n",
    "decimal_places = [len(str(value).split('.')[1]) if '.' in str(value) else 0 for value in X.iloc[0]]\n",
    "\n",
    "def build_generator(input_dim, output_dim, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(512, activation='relu', input_dim=input_dim + num_classes),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(output_dim, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_discriminator(input_dim, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(512, activation='leaky_relu', input_dim=input_dim + num_classes),\n",
    "        layers.Dense(256, activation='leaky_relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "z_dim = 100 \n",
    "X_dim = X.shape[1] \n",
    "num_classes = 2 \n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001 \n",
    "patience = 25 \n",
    "\n",
    "generator = build_generator(z_dim, X_dim, num_classes)\n",
    "discriminator = build_discriminator(X_dim, num_classes)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "D_losses = []\n",
    "G_losses = []\n",
    "best_G_loss = float('inf') \n",
    "best_D_loss = float('inf') \n",
    "stopping_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.randint(0, X[y == 1].shape[0], batch_size)\n",
    "    real_samples = X[y == 1].iloc[idx].values\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "    z = np.random.randn(batch_size, z_dim)\n",
    "    labels = np.zeros((batch_size, num_classes))\n",
    "    labels[:, 1] = 1 \n",
    "    noise_with_labels = np.concatenate((z, labels), axis=1) \n",
    "    fake_samples = generator(noise_with_labels)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        noise = tf.random.normal(shape=tf.shape(real_samples), mean=0.0, stddev=0.01)\n",
    "        D_real_loss = loss_fn(real_labels, discriminator(tf.concat([real_samples + noise, np.ones((batch_size, num_classes))], axis=1)))\n",
    "        D_fake_loss = loss_fn(np.zeros((batch_size, 1)), discriminator(tf.concat([fake_samples, np.zeros((batch_size, num_classes))], axis=1)))\n",
    "        D_loss = D_real_loss + D_fake_loss\n",
    "    D_gradients = tape.gradient(D_loss, discriminator.trainable_weights)\n",
    "    discriminator_optimizer.apply_gradients(zip(D_gradients, discriminator.trainable_weights))\n",
    "\n",
    "    z = np.random.randn(batch_size, z_dim)\n",
    "    labels = np.zeros((batch_size, num_classes))\n",
    "    labels[:, 1] = 1 \n",
    "    noise_with_labels = np.concatenate((z, labels), axis=1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_samples = generator(noise_with_labels)\n",
    "        G_loss = loss_fn(real_labels, discriminator(tf.concat([fake_samples, np.zeros((batch_size, num_classes))], axis=1)))\n",
    "    G_gradients = tape.gradient(G_loss, generator.trainable_weights)\n",
    "    generator_optimizer.apply_gradients(zip(G_gradients, generator.trainable_weights))\n",
    "\n",
    "    D_losses.append(D_loss.numpy())\n",
    "    G_losses.append(G_loss.numpy())\n",
    "\n",
    "    if G_loss < best_G_loss:\n",
    "        best_G_loss = G_loss\n",
    "        stopping_counter = 0 \n",
    "    else:\n",
    "        stopping_counter += 1\n",
    "\n",
    "    if D_loss < best_D_loss:\n",
    "        best_D_loss = D_loss\n",
    "        stopping_counter = 0\n",
    "    else:\n",
    "        stopping_counter += 1\n",
    "\n",
    "    if stopping_counter >= patience:\n",
    "        print(f\"训练提前结束，达到最佳生成器损失: {best_G_loss} 和判别器损失: {best_D_loss}。\")\n",
    "        break\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}, D_loss: {D_loss}, G_loss: {G_loss}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(D_losses, label='Discriminator loss')\n",
    "plt.plot(G_losses, label='Generator loss')\n",
    "plt.title('Changes of CGAN train loss')\n",
    "plt.xlabel('Train iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/picture/data_aug/cagn_loss.png', dpi=300)\n",
    "plt.show()        \n",
    "        \n",
    "desired_minority_count = Counter(y)[0]\n",
    "num_samples_to_generate = desired_minority_count - Counter(y)[1]\n",
    "\n",
    "z = np.random.randn(num_samples_to_generate, z_dim)\n",
    "labels = np.zeros((num_samples_to_generate, num_classes))\n",
    "labels[:, 1] = 1 \n",
    "noise_with_labels = np.concatenate((z, labels), axis=1)\n",
    "generated_samples = generator(noise_with_labels)\n",
    "\n",
    "generated_samples = generated_samples * (X_max - X_min) + X_min\n",
    "\n",
    "generated_samples = generated_samples.numpy()\n",
    "formatted_samples = np.array([np.round(col, decimals=dec) for col, dec in zip(generated_samples.T, decimal_places)]).T\n",
    "\n",
    "df_original = pd.DataFrame(X, columns=X.columns)\n",
    "integer_columns = ['WellName', 'WellType', 'Layer', 'Lithology', 'Formation']\n",
    "for i, col in enumerate(df_original.columns):\n",
    "    if col in integer_columns:\n",
    "        formatted_samples[:, i] = formatted_samples[:, i].astype(int)\n",
    "\n",
    "X_augmented = np.vstack([X, formatted_samples])\n",
    "y_augmented = np.hstack([y, np.ones(formatted_samples.shape[0])])\n",
    "\n",
    "data_before = pd.DataFrame({'Category': y, 'Type': ['Before augmentation'] * len(y)})\n",
    "data_after = pd.DataFrame({'Category': y_augmented, 'Type': ['After augmentation'] * len(y_augmented)})\n",
    "data = pd.concat([data_before, data_after])\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.countplot(data=data, x='Category', hue='Type', ax=ax, palette=['#3498db', '#2ecc71'])\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['0', '1'])\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = int(p.get_height())\n",
    "    if height > 0: \n",
    "        ax.annotate(f'{height}', \n",
    "                    (p.get_x() + p.get_width() / 2., height), \n",
    "                    ha='center', va='bottom', color='black')\n",
    "ax.set_title(\"Category distribution before and after data augmentation\")\n",
    "ax.set_xlabel(\"Category\")\n",
    "ax.set_ylabel(\"Number of Samples\")\n",
    "ax.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/picture/data_aug/category_distribution.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "df_augmented = pd.DataFrame(X_augmented, columns=X.columns)\n",
    "df_augmented['LostCirculation'] = y_augmented\n",
    "\n",
    "output_path = 'E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/data/Well_B_cgan_best.csv'\n",
    "df_augmented.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"增强后的数据已保存至: {output_path}\")\n",
    "\n",
    "def plot_all_features_comparison_save(X, generated_samples, save_dir='E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/picture/data_aug/'):\n",
    "    import os\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if not isinstance(X, pd.DataFrame) or not isinstance(generated_samples, pd.DataFrame):\n",
    "        raise ValueError(\"输入的数据集必须都是 pandas DataFrame 类型\")\n",
    "    if set(X.columns) != set(generated_samples.columns):\n",
    "        raise KeyError(\"两个数据集的特征列名不一致，无法进行对比。\")\n",
    "    available_styles = plt.style.available\n",
    "    chosen_style = 'ggplot' if 'ggplot' in available_styles else 'default'\n",
    "    plt.style.use(chosen_style)\n",
    "    for feature in X.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(X[feature], color='green', label='Raw data', kde=True, alpha=0.5)\n",
    "        sns.histplot(generated_samples[feature], color='pink', label='Augmented data', kde=True, alpha=0.5)\n",
    "        plt.title(f'Comparison via histogram - {feature}')\n",
    "        plt.xlabel(feature,color='black')\n",
    "        plt.ylabel('Frequency',color='black')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, f'{feature}_comparison.png')\n",
    "        plt.savefig(save_path,dpi=300)\n",
    "        plt.show()\n",
    "        plt.close() \n",
    "    print(f\"所有特征对比图已保存至文件夹: {save_dir}\")\n",
    "\n",
    "plot_all_features_comparison_save(df, df_augmented)\n",
    "\n",
    "generator.save('E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/model/cgan_generator.h5')\n",
    "discriminator.save('E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/model/cgan_discriminator.h5')\n",
    "print(\"生成器和判别器模型已保存。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c83ec2",
   "metadata": {},
   "source": [
    "# 1.2 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e914963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 12 \n",
    "plt.rcParams['font.weight'] = 'bold' \n",
    "plt.rcParams['axes.titlesize'] = 14  \n",
    "plt.rcParams['axes.labelsize'] = 12   \n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['legend.title_fontsize'] = 12\n",
    "\n",
    "df = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/data/Well_B_MLR.csv')\n",
    "\n",
    "if 'LostCirculation' not in df.columns:\n",
    "    raise ValueError(\"数据集必须包含 'LostCirculation' 列。\")\n",
    "X = df.drop('LostCirculation', axis=1)\n",
    "y = df['LostCirculation']\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "data_before = pd.DataFrame({'Category': y, 'Type': ['Before augmentation'] * len(y)})\n",
    "data_after = pd.DataFrame({'Category': y_resampled, 'Type': ['After augmentation'] * len(y_resampled)})\n",
    "data = pd.concat([data_before, data_after])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.countplot(data=data, x='Category', hue='Type', ax=ax, palette=['#3498db', '#2ecc71'])\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['0', '1'])\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = int(p.get_height())\n",
    "    if height > 0:\n",
    "        ax.annotate(f'{height}', \n",
    "                    (p.get_x() + p.get_width() / 2., height), \n",
    "                    ha='center', va='bottom', color='black')\n",
    "\n",
    "ax.set_title(\"Category distribution before and after SMOTE augmentation\")\n",
    "ax.set_xlabel(\"Category\")\n",
    "ax.set_ylabel(\"Number of Samples\")\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/picture/data_aug/category_distribution_smote.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "df_augmented = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_augmented['LostCirculation'] = y_resampled\n",
    "\n",
    "output_path = 'E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/data/Well_B_smote.csv'\n",
    "df_augmented.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"增强后的数据已保存至: {output_path}\")\n",
    "\n",
    "def plot_all_features_comparison_save(X, generated_samples, save_dir='E:/jupyter/lost_circulation/records/paper-bhyt/Diagnosis/picture/data_aug/'):\n",
    "    import os\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    if not isinstance(X, pd.DataFrame) or not isinstance(generated_samples, pd.DataFrame):\n",
    "        raise ValueError(\"输入的数据集必须都是 pandas DataFrame 类型\")\n",
    "\n",
    "    if set(X.columns) != set(generated_samples.columns):\n",
    "        raise KeyError(\"两个数据集的特征列名不一致，无法进行对比。\")\n",
    "\n",
    "    available_styles = plt.style.available\n",
    "    chosen_style = 'ggplot' if 'ggplot' in available_styles else 'default'\n",
    "    plt.style.use(chosen_style)\n",
    "\n",
    "    for feature in X.columns:\n",
    "        plt.figure(figsize=(8, 6)) \n",
    "        sns.histplot(X[feature], color='green', label='Raw data', kde=True, alpha=0.5)\n",
    "        sns.histplot(generated_samples[feature], color='pink', label='Augmented data', kde=True, alpha=0.5)\n",
    "        plt.title(f'Comparison via histogram - {feature}')\n",
    "        plt.xlabel(feature,color='black')\n",
    "        plt.ylabel('Frequency',color='black')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, f'{feature}_comparison_smote.png')\n",
    "        plt.savefig(save_path,dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    print(f\"所有特征对比图已保存至文件夹: {save_dir}\")\n",
    "\n",
    "plot_all_features_comparison_save(df, df_augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531a783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd8fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
